{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c47bbb",
   "metadata": {},
   "source": [
    "## Import et configurations MlFlows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0917b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 7\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:5555\"  \n",
    "EXPERIMENT_NAME = \"stockout_substitution_hyperopt_classifier_ranker_6\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"Expérience '{EXPERIMENT_NAME}' introuvable\")\n",
    "\n",
    "EXPERIMENT_ID = experiment.experiment_id\n",
    "print(\"Experiment ID:\", EXPERIMENT_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54108a26",
   "metadata": {},
   "source": [
    "## Chargement de tous les runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b27f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 runs chargés\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.ndcg_at_1</th>\n",
       "      <th>metrics.best_iteration</th>\n",
       "      <th>metrics.hit_rate_at_5</th>\n",
       "      <th>metrics.ndcg_at_3</th>\n",
       "      <th>metrics.hit_rate_at_3</th>\n",
       "      <th>metrics.hit_rate_at_1</th>\n",
       "      <th>metrics.ndcg_at_5</th>\n",
       "      <th>metrics.recall</th>\n",
       "      <th>metrics.logloss</th>\n",
       "      <th>metrics.f1</th>\n",
       "      <th>metrics.precision</th>\n",
       "      <th>metrics.auc</th>\n",
       "      <th>metrics.pr_auc</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.num_leaves</th>\n",
       "      <th>params.min_child_samples</th>\n",
       "      <th>params.n_estimators</th>\n",
       "      <th>params.subsample</th>\n",
       "      <th>params.colsample_bytree</th>\n",
       "      <th>params.rsm</th>\n",
       "      <th>params.l2_leaf_reg</th>\n",
       "      <th>params.iterations</th>\n",
       "      <th>params.depth</th>\n",
       "      <th>params.reg_alpha</th>\n",
       "      <th>params.reg_lambda</th>\n",
       "      <th>params.min_child_weight</th>\n",
       "      <th>params.max_depth</th>\n",
       "      <th>params.C</th>\n",
       "      <th>params.penalty</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.model_name</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.model_type</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46ad7c66a9484c7a84cf379747c88287</td>\n",
       "      <td>7</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>mlflow-artifacts:/7/46ad7c66a9484c7a84cf379747...</td>\n",
       "      <td>2026-01-07 09:34:49.919000+00:00</td>\n",
       "      <td>2026-01-07 09:34:53.200000+00:00</td>\n",
       "      <td>0.636238</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.715670</td>\n",
       "      <td>0.855774</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.636238</td>\n",
       "      <td>0.886897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>eric</td>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>valuable-conch-790</td>\n",
       "      <td>ranking</td>\n",
       "      <td>/home/eric/.cache/pypoetry/virtualenvs/algo-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5910e6f65ad645ffb5716d529b2608d4</td>\n",
       "      <td>7</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>mlflow-artifacts:/7/5910e6f65ad645ffb5716d529b...</td>\n",
       "      <td>2026-01-07 09:34:46.602000+00:00</td>\n",
       "      <td>2026-01-07 09:34:49.815000+00:00</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.715757</td>\n",
       "      <td>0.856644</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>0.887357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>eric</td>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>honorable-smelt-850</td>\n",
       "      <td>ranking</td>\n",
       "      <td>/home/eric/.cache/pypoetry/virtualenvs/algo-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d55f3ce4a104f3cbaa7716234813ae2</td>\n",
       "      <td>7</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>mlflow-artifacts:/7/1d55f3ce4a104f3cbaa7716234...</td>\n",
       "      <td>2026-01-07 09:34:43.218000+00:00</td>\n",
       "      <td>2026-01-07 09:34:46.504000+00:00</td>\n",
       "      <td>0.638141</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.715670</td>\n",
       "      <td>0.857083</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.638141</td>\n",
       "      <td>0.887685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>eric</td>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>secretive-ape-612</td>\n",
       "      <td>ranking</td>\n",
       "      <td>/home/eric/.cache/pypoetry/virtualenvs/algo-re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status                                       artifact_uri                       start_time                         end_time  metrics.ndcg_at_1  \\\n",
       "0  46ad7c66a9484c7a84cf379747c88287             7  FINISHED  mlflow-artifacts:/7/46ad7c66a9484c7a84cf379747... 2026-01-07 09:34:49.919000+00:00 2026-01-07 09:34:53.200000+00:00           0.636238   \n",
       "1  5910e6f65ad645ffb5716d529b2608d4             7  FINISHED  mlflow-artifacts:/7/5910e6f65ad645ffb5716d529b... 2026-01-07 09:34:46.602000+00:00 2026-01-07 09:34:49.815000+00:00           0.637536   \n",
       "2  1d55f3ce4a104f3cbaa7716234813ae2             7  FINISHED  mlflow-artifacts:/7/1d55f3ce4a104f3cbaa7716234... 2026-01-07 09:34:43.218000+00:00 2026-01-07 09:34:46.504000+00:00           0.638141   \n",
       "\n",
       "   metrics.best_iteration  metrics.hit_rate_at_5  metrics.ndcg_at_3  metrics.hit_rate_at_3  metrics.hit_rate_at_1  metrics.ndcg_at_5  metrics.recall  metrics.logloss  metrics.f1  metrics.precision  \\\n",
       "0                     4.0               0.715670           0.855774               0.712296               0.636238           0.886897             NaN              NaN         NaN                NaN   \n",
       "1                    17.0               0.715757           0.856644               0.712296               0.637536           0.887357             NaN              NaN         NaN                NaN   \n",
       "2                    15.0               0.715670           0.857083               0.712296               0.638141           0.887685             NaN              NaN         NaN                NaN   \n",
       "\n",
       "   metrics.auc  metrics.pr_auc params.learning_rate params.num_leaves params.min_child_samples params.n_estimators params.subsample params.colsample_bytree params.rsm params.l2_leaf_reg  \\\n",
       "0          NaN             NaN                  0.1                63                      100                 500              0.7                     1.0       None               None   \n",
       "1          NaN             NaN                 0.05                31                      100                 500              1.0                     0.7       None               None   \n",
       "2          NaN             NaN                  0.1                31                       20                1000              0.9                     0.9       None               None   \n",
       "\n",
       "  params.iterations params.depth params.reg_alpha params.reg_lambda params.min_child_weight params.max_depth params.C params.penalty tags.mlflow.source.type tags.mlflow.user tags.model_name  \\\n",
       "0              None         None             None              None                    None             None     None           None                   LOCAL             eric      LGBMRanker   \n",
       "1              None         None             None              None                    None             None     None           None                   LOCAL             eric      LGBMRanker   \n",
       "2              None         None             None              None                    None             None     None           None                   LOCAL             eric      LGBMRanker   \n",
       "\n",
       "   tags.mlflow.runName tags.model_type                            tags.mlflow.source.name  \n",
       "0   valuable-conch-790         ranking  /home/eric/.cache/pypoetry/virtualenvs/algo-re...  \n",
       "1  honorable-smelt-850         ranking  /home/eric/.cache/pypoetry/virtualenvs/algo-re...  \n",
       "2    secretive-ape-612         ranking  /home/eric/.cache/pypoetry/virtualenvs/algo-re...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[EXPERIMENT_ID],\n",
    "    output_format=\"pandas\"\n",
    ")\n",
    "\n",
    "print(f\"{len(runs)} runs chargés\")\n",
    "runs.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0e94a",
   "metadata": {},
   "source": [
    "## Colonnes utiles et nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4899dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>status</th>\n",
       "      <th>start_time</th>\n",
       "      <th>ndcg_at_1</th>\n",
       "      <th>best_iteration</th>\n",
       "      <th>hit_rate_at_5</th>\n",
       "      <th>ndcg_at_3</th>\n",
       "      <th>hit_rate_at_3</th>\n",
       "      <th>hit_rate_at_1</th>\n",
       "      <th>ndcg_at_5</th>\n",
       "      <th>recall</th>\n",
       "      <th>logloss</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>l2_leaf_reg</th>\n",
       "      <th>iterations</th>\n",
       "      <th>depth</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>mlflow.source.type</th>\n",
       "      <th>mlflow.user</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mlflow.runName</th>\n",
       "      <th>model_type</th>\n",
       "      <th>mlflow.source.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46ad7c66a9484c7a84cf379747c88287</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>2026-01-07 09:34:49.919000+00:00</td>\n",
       "      <td>0.636238</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.715670</td>\n",
       "      <td>0.855774</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.636238</td>\n",
       "      <td>0.886897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>eric</td>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>valuable-conch-790</td>\n",
       "      <td>ranking</td>\n",
       "      <td>/home/eric/.cache/pypoetry/virtualenvs/algo-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5910e6f65ad645ffb5716d529b2608d4</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>2026-01-07 09:34:46.602000+00:00</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.715757</td>\n",
       "      <td>0.856644</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>0.887357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>eric</td>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>honorable-smelt-850</td>\n",
       "      <td>ranking</td>\n",
       "      <td>/home/eric/.cache/pypoetry/virtualenvs/algo-re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id    status                       start_time  ndcg_at_1  best_iteration  hit_rate_at_5  ndcg_at_3  hit_rate_at_3  hit_rate_at_1  ndcg_at_5  recall  logloss  f1  \\\n",
       "0  46ad7c66a9484c7a84cf379747c88287  FINISHED 2026-01-07 09:34:49.919000+00:00   0.636238             4.0       0.715670   0.855774       0.712296       0.636238   0.886897     NaN      NaN NaN   \n",
       "1  5910e6f65ad645ffb5716d529b2608d4  FINISHED 2026-01-07 09:34:46.602000+00:00   0.637536            17.0       0.715757   0.856644       0.712296       0.637536   0.887357     NaN      NaN NaN   \n",
       "\n",
       "   precision  auc  pr_auc learning_rate num_leaves min_child_samples n_estimators subsample colsample_bytree   rsm l2_leaf_reg iterations depth reg_alpha reg_lambda min_child_weight max_depth     C  \\\n",
       "0        NaN  NaN     NaN           0.1         63               100          500       0.7              1.0  None        None       None  None      None       None             None      None  None   \n",
       "1        NaN  NaN     NaN          0.05         31               100          500       1.0              0.7  None        None       None  None      None       None             None      None  None   \n",
       "\n",
       "  penalty mlflow.source.type mlflow.user  model_name       mlflow.runName model_type                                 mlflow.source.name  \n",
       "0    None              LOCAL        eric  LGBMRanker   valuable-conch-790    ranking  /home/eric/.cache/pypoetry/virtualenvs/algo-re...  \n",
       "1    None              LOCAL        eric  LGBMRanker  honorable-smelt-850    ranking  /home/eric/.cache/pypoetry/virtualenvs/algo-re...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_cols = [c for c in runs.columns if c.startswith(\"metrics.\")]\n",
    "param_cols = [c for c in runs.columns if c.startswith(\"params.\")]\n",
    "tag_cols   = [c for c in runs.columns if c.startswith(\"tags.\")]\n",
    "\n",
    "cols = (\n",
    "    [\"run_id\", \"status\", \"start_time\"] +\n",
    "    metric_cols +\n",
    "    param_cols +\n",
    "    tag_cols\n",
    ")\n",
    "\n",
    "df = runs[cols].copy()\n",
    "\n",
    "# Simplification des noms\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.replace(\"metrics.\", \"\", regex=False)\n",
    "      .str.replace(\"params.\", \"\", regex=False)\n",
    "      .str.replace(\"tags.\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884c7c7",
   "metadata": {},
   "source": [
    "## Separation Ranker et Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ccde07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers: 81\n",
      "Rankers: 20\n"
     ]
    }
   ],
   "source": [
    "df[\"model_type\"] = df.get(\"model_type\", \"unknown\")\n",
    "df[\"model_name\"] = df.get(\"model_name\", \"unknown\")\n",
    "\n",
    "df_classif = df[df[\"model_type\"] == \"classification\"].copy()\n",
    "df_ranker  = df[df[\"model_type\"] == \"ranking\"].copy()\n",
    "\n",
    "print(\"Classifiers:\", len(df_classif))\n",
    "print(\"Rankers:\", len(df_ranker))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8505a",
   "metadata": {},
   "source": [
    "## Analyse Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34d51b",
   "metadata": {},
   "source": [
    "Métriques disponibles:\n",
    "- auc\n",
    "- pr_auc\n",
    "- logloss\n",
    "- precision\n",
    "- recall\n",
    "- f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1c466",
   "metadata": {},
   "source": [
    "#### Top modèles par AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e843bf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.728301</td>\n",
       "      <td>0.790296</td>\n",
       "      <td>0.697076</td>\n",
       "      <td>0.694752</td>\n",
       "      <td>0.699416</td>\n",
       "      <td>0.593348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.728088</td>\n",
       "      <td>0.790238</td>\n",
       "      <td>0.696270</td>\n",
       "      <td>0.695968</td>\n",
       "      <td>0.696572</td>\n",
       "      <td>0.593361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.727761</td>\n",
       "      <td>0.789836</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.695860</td>\n",
       "      <td>0.700916</td>\n",
       "      <td>0.593617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.727048</td>\n",
       "      <td>0.789316</td>\n",
       "      <td>0.695649</td>\n",
       "      <td>0.696227</td>\n",
       "      <td>0.695072</td>\n",
       "      <td>0.594013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.726991</td>\n",
       "      <td>0.789142</td>\n",
       "      <td>0.696120</td>\n",
       "      <td>0.697251</td>\n",
       "      <td>0.694993</td>\n",
       "      <td>0.594209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>0.789323</td>\n",
       "      <td>0.692552</td>\n",
       "      <td>0.696312</td>\n",
       "      <td>0.688833</td>\n",
       "      <td>0.594369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>0.789323</td>\n",
       "      <td>0.692552</td>\n",
       "      <td>0.696312</td>\n",
       "      <td>0.688833</td>\n",
       "      <td>0.594369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.726716</td>\n",
       "      <td>0.788943</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>0.696407</td>\n",
       "      <td>0.693492</td>\n",
       "      <td>0.594460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.726598</td>\n",
       "      <td>0.788784</td>\n",
       "      <td>0.694937</td>\n",
       "      <td>0.695515</td>\n",
       "      <td>0.694361</td>\n",
       "      <td>0.594439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.725739</td>\n",
       "      <td>0.788125</td>\n",
       "      <td>0.693279</td>\n",
       "      <td>0.697379</td>\n",
       "      <td>0.689228</td>\n",
       "      <td>0.595311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name       auc    pr_auc        f1  precision    recall   logloss\n",
       "21  CatBoostClassifier  0.728301  0.790296  0.697076   0.694752  0.699416  0.593348\n",
       "33  CatBoostClassifier  0.728088  0.790238  0.696270   0.695968  0.696572  0.593361\n",
       "25  CatBoostClassifier  0.727761  0.789836  0.698379   0.695860  0.700916  0.593617\n",
       "75       XGBClassifier  0.727048  0.789316  0.695649   0.696227  0.695072  0.594013\n",
       "64       XGBClassifier  0.726991  0.789142  0.696120   0.697251  0.694993  0.594209\n",
       "24  CatBoostClassifier  0.726738  0.789323  0.692552   0.696312  0.688833  0.594369\n",
       "31  CatBoostClassifier  0.726738  0.789323  0.692552   0.696312  0.688833  0.594369\n",
       "71       XGBClassifier  0.726716  0.788943  0.694947   0.696407  0.693492  0.594460\n",
       "69       XGBClassifier  0.726598  0.788784  0.694937   0.695515  0.694361  0.594439\n",
       "62       XGBClassifier  0.725739  0.788125  0.693279   0.697379  0.689228  0.595311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classif_sorted = (\n",
    "    df_classif\n",
    "    .sort_values(\"auc\", ascending=False)\n",
    ")\n",
    "\n",
    "df_classif_sorted[\n",
    "    [\"model_name\", \"auc\", \"pr_auc\", \"f1\", \"precision\", \"recall\", \"logloss\"]\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a54f8",
   "metadata": {},
   "source": [
    "Observations clés:\n",
    "\n",
    "AUC max ≈ 0.728 → performance correcte mais pas “state of the art”\n",
    "\n",
    "CatBoost et XGBoost dominent clairement\n",
    "\n",
    "Les écarts sont très faibles entre les meilleurs runs (≈ 0.002 d’AUC)\n",
    "\n",
    "Lecture des métriques (meilleur run CatBoost – id 21)\n",
    "\n",
    "AUC = 0.7283\n",
    "→ Bonne capacité de discrimination globale\n",
    "\n",
    "PR-AUC = 0.7903\n",
    "→ Solide si classes déséquilibrées\n",
    "\n",
    "F1 ≈ 0.697\n",
    "→ Bon compromis précision / rappel\n",
    "\n",
    "Precision ≈ Recall ≈ 0.695–0.700\n",
    "→ Modèle bien équilibré\n",
    "\n",
    "Logloss ≈ 0.593\n",
    "→ Probabilités plutôt bien calibrées\n",
    "\n",
    "Conclusion\n",
    "\n",
    "- CatBoostClassifier est légèrement supérieur, mais XGBClassifier est quasiment équivalent.\n",
    "- Les différences sont non significatives statistiquement sans test plus poussé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ce401",
   "metadata": {},
   "source": [
    "#### Moyenne performance par modèle (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbe6fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.716703</td>\n",
       "      <td>0.781907</td>\n",
       "      <td>0.687279</td>\n",
       "      <td>0.688384</td>\n",
       "      <td>0.686203</td>\n",
       "      <td>0.605323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.781355</td>\n",
       "      <td>0.687522</td>\n",
       "      <td>0.689430</td>\n",
       "      <td>0.685642</td>\n",
       "      <td>0.605999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.711249</td>\n",
       "      <td>0.777924</td>\n",
       "      <td>0.682801</td>\n",
       "      <td>0.685932</td>\n",
       "      <td>0.679723</td>\n",
       "      <td>0.610106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.699013</td>\n",
       "      <td>0.761051</td>\n",
       "      <td>0.687202</td>\n",
       "      <td>0.671237</td>\n",
       "      <td>0.703945</td>\n",
       "      <td>0.619595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         auc    pr_auc        f1  precision    recall   logloss\n",
       "model_name                                                                     \n",
       "XGBClassifier       0.716703  0.781907  0.687279   0.688384  0.686203  0.605323\n",
       "CatBoostClassifier  0.715695  0.781355  0.687522   0.689430  0.685642  0.605999\n",
       "LGBMClassifier      0.711249  0.777924  0.682801   0.685932  0.679723  0.610106\n",
       "LogReg              0.699013  0.761051  0.687202   0.671237  0.703945  0.619595"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_summary = (\n",
    "    df_classif\n",
    "    .groupby(\"model_name\")[[\"auc\", \"pr_auc\", \"f1\", \"precision\", \"recall\", \"logloss\"]]\n",
    "    .mean()\n",
    "    .sort_values(\"auc\", ascending=False)\n",
    ")\n",
    "\n",
    "classif_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90131b7",
   "metadata": {},
   "source": [
    "Interprétation\n",
    "\n",
    "XGB et CatBoost sont équivalents en moyenne\n",
    "\n",
    "CatBoost :\n",
    "- meilleure précision\n",
    "- meilleur F1 moyen\n",
    "\n",
    "XGB :\n",
    "- meilleur AUC moyen\n",
    "- meilleur logloss → meilleure calibration\n",
    "\n",
    "LogReg :\n",
    "- recall élevé\n",
    "- mais AUC et logloss faibles → modèle trop simple\n",
    "\n",
    "Conclusion\n",
    "- CatBoost / XGB = meilleur compromis global\n",
    "- LogReg utile seulement si le recall est prioritaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13681e",
   "metadata": {},
   "source": [
    "#### Meilleur run par modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13461f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.728301</td>\n",
       "      <td>0.790296</td>\n",
       "      <td>0.697076</td>\n",
       "      <td>0.694752</td>\n",
       "      <td>0.699416</td>\n",
       "      <td>0.593348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.727048</td>\n",
       "      <td>0.789316</td>\n",
       "      <td>0.695649</td>\n",
       "      <td>0.696227</td>\n",
       "      <td>0.695072</td>\n",
       "      <td>0.594013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.724540</td>\n",
       "      <td>0.787475</td>\n",
       "      <td>0.690771</td>\n",
       "      <td>0.693520</td>\n",
       "      <td>0.688043</td>\n",
       "      <td>0.595991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.699072</td>\n",
       "      <td>0.761048</td>\n",
       "      <td>0.686965</td>\n",
       "      <td>0.670882</td>\n",
       "      <td>0.703838</td>\n",
       "      <td>0.619660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name       auc    pr_auc        f1  precision    recall   logloss\n",
       "21  CatBoostClassifier  0.728301  0.790296  0.697076   0.694752  0.699416  0.593348\n",
       "75       XGBClassifier  0.727048  0.789316  0.695649   0.696227  0.695072  0.594013\n",
       "57      LGBMClassifier  0.724540  0.787475  0.690771   0.693520  0.688043  0.595991\n",
       "80              LogReg  0.699072  0.761048  0.686965   0.670882  0.703838  0.619660"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classif_runs = (\n",
    "    df_classif\n",
    "    .sort_values(\"auc\", ascending=False)\n",
    "    .groupby(\"model_name\")\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "best_classif_runs[\n",
    "    [\"model_name\", \"auc\", \"pr_auc\", \"f1\", \"precision\", \"recall\", \"logloss\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34fb061",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- CatBoostClassifier (run 21) est le meilleur choix\n",
    "- XGB est une alternative quasi équivalente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cc511",
   "metadata": {},
   "source": [
    "## Analyse des Rankers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1b275",
   "metadata": {},
   "source": [
    "Métriques disponibles:\n",
    "- ndcg_at_1\n",
    "- ndcg_at_3\n",
    "- ndcg_at_5\n",
    "- hit_rate_at_1\n",
    "- hit_rate_at_3\n",
    "- hit_rate_at_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f4b26",
   "metadata": {},
   "source": [
    "#### Top runs par NDCG@3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f6420e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>ndcg_at_1</th>\n",
       "      <th>ndcg_at_3</th>\n",
       "      <th>ndcg_at_5</th>\n",
       "      <th>hit_rate_at_1</th>\n",
       "      <th>hit_rate_at_3</th>\n",
       "      <th>hit_rate_at_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.638055</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.887532</td>\n",
       "      <td>0.638055</td>\n",
       "      <td>0.712382</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.638228</td>\n",
       "      <td>0.857165</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.638228</td>\n",
       "      <td>0.712988</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.638141</td>\n",
       "      <td>0.857083</td>\n",
       "      <td>0.887685</td>\n",
       "      <td>0.638141</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.715670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.637709</td>\n",
       "      <td>0.856951</td>\n",
       "      <td>0.887459</td>\n",
       "      <td>0.637709</td>\n",
       "      <td>0.712555</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.637709</td>\n",
       "      <td>0.856896</td>\n",
       "      <td>0.887479</td>\n",
       "      <td>0.637709</td>\n",
       "      <td>0.712469</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.637622</td>\n",
       "      <td>0.856866</td>\n",
       "      <td>0.887557</td>\n",
       "      <td>0.637622</td>\n",
       "      <td>0.712209</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.637882</td>\n",
       "      <td>0.856764</td>\n",
       "      <td>0.887377</td>\n",
       "      <td>0.637882</td>\n",
       "      <td>0.712555</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>0.856644</td>\n",
       "      <td>0.887357</td>\n",
       "      <td>0.637536</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.635892</td>\n",
       "      <td>0.856134</td>\n",
       "      <td>0.886727</td>\n",
       "      <td>0.635892</td>\n",
       "      <td>0.712123</td>\n",
       "      <td>0.715670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.635373</td>\n",
       "      <td>0.855933</td>\n",
       "      <td>0.886806</td>\n",
       "      <td>0.635373</td>\n",
       "      <td>0.712382</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  ndcg_at_1  ndcg_at_3  ndcg_at_5  hit_rate_at_1  hit_rate_at_3  hit_rate_at_5\n",
       "18  LGBMRanker   0.638055   0.857388   0.887532       0.638055       0.712382       0.715757\n",
       "17  LGBMRanker   0.638228   0.857165   0.887528       0.638228       0.712988       0.715757\n",
       "2   LGBMRanker   0.638141   0.857083   0.887685       0.638141       0.712296       0.715670\n",
       "12  LGBMRanker   0.637709   0.856951   0.887459       0.637709       0.712555       0.715757\n",
       "7   LGBMRanker   0.637709   0.856896   0.887479       0.637709       0.712469       0.715757\n",
       "6   LGBMRanker   0.637622   0.856866   0.887557       0.637622       0.712209       0.715757\n",
       "10  LGBMRanker   0.637882   0.856764   0.887377       0.637882       0.712555       0.715757\n",
       "1   LGBMRanker   0.637536   0.856644   0.887357       0.637536       0.712296       0.715757\n",
       "3   LGBMRanker   0.635892   0.856134   0.886727       0.635892       0.712123       0.715670\n",
       "14  LGBMRanker   0.635373   0.855933   0.886806       0.635373       0.712382       0.715757"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_sorted = df_ranker.sort_values(\"ndcg_at_3\", ascending=False)\n",
    "\n",
    "df_ranker_sorted[\n",
    "    [\"model_name\", \"ndcg_at_1\", \"ndcg_at_3\", \"ndcg_at_5\",\n",
    "     \"hit_rate_at_1\", \"hit_rate_at_3\", \"hit_rate_at_5\"]\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16d71b",
   "metadata": {},
   "source": [
    "#### Moyenne des performances Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914efb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg_at_1</th>\n",
       "      <th>ndcg_at_3</th>\n",
       "      <th>ndcg_at_5</th>\n",
       "      <th>hit_rate_at_1</th>\n",
       "      <th>hit_rate_at_3</th>\n",
       "      <th>hit_rate_at_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRanker</th>\n",
       "      <td>0.636467</td>\n",
       "      <td>0.855982</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.636467</td>\n",
       "      <td>0.7123</td>\n",
       "      <td>0.715718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ndcg_at_1  ndcg_at_3  ndcg_at_5  hit_rate_at_1  hit_rate_at_3  hit_rate_at_5\n",
       "model_name                                                                              \n",
       "LGBMRanker   0.636467   0.855982   0.886821       0.636467         0.7123       0.715718"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_summary = (\n",
    "    df_ranker\n",
    "    .groupby(\"model_name\")[\n",
    "        [\"ndcg_at_1\", \"ndcg_at_3\", \"ndcg_at_5\",\n",
    "         \"hit_rate_at_1\", \"hit_rate_at_3\", \"hit_rate_at_5\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .sort_values(\"ndcg_at_3\", ascending=False)\n",
    ")\n",
    "\n",
    "ranker_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd84b4",
   "metadata": {},
   "source": [
    "#### Meilleur run par Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ffbc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>ndcg_at_1</th>\n",
       "      <th>ndcg_at_3</th>\n",
       "      <th>ndcg_at_5</th>\n",
       "      <th>hit_rate_at_1</th>\n",
       "      <th>hit_rate_at_3</th>\n",
       "      <th>hit_rate_at_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LGBMRanker</td>\n",
       "      <td>0.638055</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.887532</td>\n",
       "      <td>0.638055</td>\n",
       "      <td>0.712382</td>\n",
       "      <td>0.715757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  ndcg_at_1  ndcg_at_3  ndcg_at_5  hit_rate_at_1  hit_rate_at_3  hit_rate_at_5\n",
       "18  LGBMRanker   0.638055   0.857388   0.887532       0.638055       0.712382       0.715757"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ranker_runs = (\n",
    "    df_ranker\n",
    "    .sort_values(\"ndcg_at_3\", ascending=False)\n",
    "    .groupby(\"model_name\")\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "best_ranker_runs[\n",
    "    [\"model_name\", \"ndcg_at_1\", \"ndcg_at_3\", \"ndcg_at_5\",\n",
    "     \"hit_rate_at_1\", \"hit_rate_at_3\", \"hit_rate_at_5\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64695d25",
   "metadata": {},
   "source": [
    "Résultats clés:\n",
    "- NDCG@3 ≈ 0.857\n",
    "- HitRate@3 ≈ 71%\n",
    "- Stabilité très forte entre runs (écarts minimes)\n",
    "\n",
    "Interprétation:\n",
    "- ~71% du temps, un item pertinent est présent dans le top 3\n",
    "- ~64% du temps, il est en top 1\n",
    "- Très bonne capacité de tri fin en tête de liste\n",
    "\n",
    "Moyenne vs meilleur run:\n",
    "- Moyenne NDCG@3 = 0.8560\n",
    "- Meilleur run NDCG@3 = 0.8574\n",
    "=> Hyperparamètres bien maîtrisés, peu de sur-optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e000cd7",
   "metadata": {},
   "source": [
    "#### Inspection des hyperparamètres du meilleur run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb1f563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndcg_at_1                                                      0.638055\n",
       "best_iteration                                                     10.0\n",
       "hit_rate_at_5                                                  0.715757\n",
       "ndcg_at_3                                                      0.857388\n",
       "hit_rate_at_3                                                  0.712382\n",
       "hit_rate_at_1                                                  0.638055\n",
       "ndcg_at_5                                                      0.887532\n",
       "learning_rate                                                       0.1\n",
       "num_leaves                                                           31\n",
       "min_child_samples                                                    50\n",
       "n_estimators                                                        500\n",
       "subsample                                                           1.0\n",
       "colsample_bytree                                                    1.0\n",
       "mlflow.source.type                                                LOCAL\n",
       "mlflow.user                                                        eric\n",
       "mlflow.runName                                           serious-doe-14\n",
       "mlflow.source.name    /home/eric/.cache/pypoetry/virtualenvs/algo-re...\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run = best_ranker_runs.iloc[0]\n",
    "\n",
    "best_params = best_run[[c for c in best_run.index if c not in [\n",
    "    \"run_id\",\"model_name\",\"model_type\",\"status\",\"start_time\"\n",
    "] and not pd.isna(best_run[c])]]\n",
    "\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e84cefd",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Classification vs Ranking — que choisir ?\n",
    "Si l'objectif est :\n",
    "\n",
    "- Décision binaire (oui/non)\n",
    "=> CatBoostClassifier\n",
    "\n",
    "- Top-K recommandations / priorisation / tri\n",
    "=> LGBMRanker\n",
    "\n",
    "\n",
    "_______\n",
    "\n",
    "\n",
    "- Le meilleur classifier selon l'AUC est : **CatBoostClassifier (run 21, AUC = 0.7283)**\n",
    "- Le meilleur ranker selon NDCG@3 est : **LGBMRanker (run 18, NDCG@3 = 0.8574)**\n",
    "- Les Rankers surpassent les classifiers en top-k → **à privilégier en prod**\n",
    "- Les classifiers restent utiles comme **baseline / fallback**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo-reco-Zao1WwXe-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

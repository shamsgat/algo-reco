{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#TODO Defined correct path\n",
    "CHEMIN_PROCCESSED_DATA_FOLDER = \"../processed/\"\n",
    "\n",
    "# 1. Charger le fichier parquet\n",
    "#TODO utilise la fonction ingestion d'Emna et Shams\n",
    "df = pd.read_parquet(CHEMIN_PROCCESSED_DATA_FOLDER+\"processed_data.parquet\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3775b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split en test et train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser en train et test (par exemple 80/20)\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier, LGBMRanker\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Pourquoi tester ces algorithmes pour la recommandation de produits\n",
    "# en cas de rupture de stock ?\n",
    "#\n",
    "# L’objectif est de prédire ou de classer les meilleurs produits de\n",
    "# substitution à proposer à un client lorsqu’un article est indisponible.\n",
    "# Nous testons plusieurs familles de modèles afin de comparer :\n",
    "#   - la capacité de généralisation,\n",
    "#   - la performance en classification et en ranking,\n",
    "#   - la robustesse face à des features hétérogènes (prix, catégorie,\n",
    "#     similarité, contexte client, etc.).\n",
    "#\n",
    "# 1) Logistic Regression\n",
    "#    - Sert de modèle baseline simple et interprétable.\n",
    "#    - Permet de vérifier que les features contiennent bien un signal\n",
    "#      prédictif (sanity check).\n",
    "#    - Facilite l’analyse des coefficients et la compréhension métier.\n",
    "#\n",
    "# 2) XGBClassifier (XGBoost)\n",
    "#    - Modèle de gradient boosting très performant sur données tabulaires.\n",
    "#    - Capable de capturer des relations non linéaires complexes entre\n",
    "#      produits et contexte client.\n",
    "#    - Sert de référence \"haut niveau\" en classification supervisée.\n",
    "#\n",
    "# 3) LGBMClassifier (LightGBM)\n",
    "#    - Alternative plus rapide et scalable au XGBoost.\n",
    "#    - Très efficace sur de grands volumes de données et de nombreuses\n",
    "#      features.\n",
    "#    - Utilisé ici pour prédire la probabilité qu’un produit substitut\n",
    "#      soit accepté par le client.\n",
    "#\n",
    "# 4) LGBMRanker (LightGBM - Learning to Rank)\n",
    "#    - Modèle spécifiquement conçu pour les problèmes de ranking.\n",
    "#    - Permet de classer plusieurs produits candidats pour une même\n",
    "#      rupture de stock et de sélectionner le meilleur (Top-1 ou Top-K).\n",
    "#    - Particulièrement adapté aux systèmes de recommandation.\n",
    "#\n",
    "# 5) CatBoostClassifier\n",
    "#    - Modèle de boosting optimisé pour les variables catégorielles.\n",
    "#    - Réduit le besoin de preprocessing (encodage) des catégories.\n",
    "#    - Souvent très performant dans les contextes e-commerce avec\n",
    "#      catégories, marques et attributs produits.\n",
    "#\n",
    "# Cette approche multi-modèles permet d’identifier le meilleur compromis\n",
    "# entre performance, interprétabilité et robustesse pour le moteur de\n",
    "# recommandation de produits de substitution.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Définir les modèles et leurs grilles de paramètres\n",
    "models = {\n",
    "\n",
    "    # =========================\n",
    "    # Logistic Regression (Baseline)\n",
    "    # =========================\n",
    "    \"LogReg\": {\n",
    "        \"model_class\": LogisticRegression,\n",
    "        \"param_grid\": {\n",
    "            \"C\": [0.1, 1.0, 10.0],\n",
    "            \"penalty\": [\"l2\"],\n",
    "        },\n",
    "        \"fixed_params\": {\n",
    "            \"solver\": \"lbfgs\",\n",
    "            \"max_iter\": 2000,\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": 42,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # =========================\n",
    "    # XGBoost Classifier\n",
    "    # =========================\n",
    "    \"XGBClassifier\": {\n",
    "        \"model_class\": XGBClassifier,\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [500, 1000],\n",
    "            \"max_depth\": [4, 6, 8],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "            \"subsample\": [0.7, 0.9, 1.0],\n",
    "            \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "            \"min_child_weight\": [1, 5, 10],\n",
    "            \"reg_alpha\": [0.0, 0.1, 1.0],\n",
    "            \"reg_lambda\": [1.0, 2.0, 5.0],\n",
    "        },\n",
    "        \"fixed_params\": {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # =========================\n",
    "    # LightGBM Classifier\n",
    "    # =========================\n",
    "    \"LGBMClassifier\": {\n",
    "        \"model_class\": LGBMClassifier,\n",
    "        \"param_grid\": {\n",
    "            \"num_leaves\": [31, 63, 127],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "            \"n_estimators\": [500, 1000],\n",
    "            \"min_child_samples\": [20, 50, 100],\n",
    "            \"subsample\": [0.7, 0.9, 1.0],\n",
    "            \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "            \"reg_alpha\": [0.0, 0.1, 1.0],\n",
    "            \"reg_lambda\": [0.0, 0.1, 1.0],\n",
    "        },\n",
    "        \"fixed_params\": {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"auc\",\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # =========================\n",
    "    # LightGBM Ranker\n",
    "    # =========================\n",
    "    \"LGBMRanker\": {\n",
    "        \"model_class\": LGBMRanker,\n",
    "        \"param_grid\": {\n",
    "            \"objective\": [\"lambdarank\"],\n",
    "            \"metric\": [\"ndcg\"],\n",
    "            \"num_leaves\": [31, 63, 127],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "            \"n_estimators\": [500, 1000],\n",
    "            \"min_child_samples\": [20, 50, 100],\n",
    "            \"subsample\": [0.7, 0.9, 1.0],\n",
    "            \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "        },\n",
    "        \"fixed_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # =========================\n",
    "    # CatBoost Classifier\n",
    "    # =========================\n",
    "    \"CatBoostClassifier\": {\n",
    "        \"model_class\": CatBoostClassifier,\n",
    "        \"param_grid\": {\n",
    "            \"depth\": [6, 8, 10],\n",
    "            \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "            \"iterations\": [500, 1000],\n",
    "            \"l2_leaf_reg\": [1, 3, 5, 9],\n",
    "            \"subsample\": [0.7, 0.9, 1.0],\n",
    "            \"rsm\": [0.7, 0.9, 1.0],\n",
    "        },\n",
    "        \"fixed_params\": {\n",
    "            \"loss_function\": \"Logloss\",\n",
    "            \"eval_metric\": \"AUC\",\n",
    "            \"random_seed\": 42,\n",
    "            \"verbose\": 0,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "# Métriques ranking simples (binaire ou grades) \n",
    "def dcg_at_k(rels, k):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    if rels.size == 0:\n",
    "        return 0.0\n",
    "    discounts = 1.0 / np.log2(np.arange(2, rels.size + 2))\n",
    "    return float(np.sum(rels * discounts))\n",
    "\n",
    "def ndcg_at_k(rels, k):\n",
    "    dcg = dcg_at_k(rels, k)\n",
    "    ideal = dcg_at_k(sorted(rels, reverse=True), k)\n",
    "    return 0.0 if ideal == 0 else float(dcg / ideal)\n",
    "\n",
    "def mrr_at_k(rels, k):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    hits = np.where(rels > 0)[0]\n",
    "    return 0.0 if hits.size == 0 else float(1.0 / (hits[0] + 1))\n",
    "\n",
    "def hit_rate_at_k(rels, k):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    return float(np.any(rels > 0))\n",
    "\n",
    "def precision_at_k(rels, k):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    return float(np.mean(rels > 0)) if rels.size else 0.0\n",
    "\n",
    "def recall_at_k(rels, k):\n",
    "    rels = np.asarray(rels)\n",
    "    total_pos = np.sum(rels > 0)\n",
    "    if total_pos == 0:\n",
    "        return 0.0\n",
    "    return float(np.sum(rels[:k] > 0) / total_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80284ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_metrics(y_true, y_score, group, ks=(1, 3, 5)):\n",
    "    \"\"\"\n",
    "    y_true: array (0/1 ou grades) trié dans le même ordre que y_score, group\n",
    "    group: liste des tailles de groupes (ex: [20, 20, 15, ...]) -> une requête = un stockout event\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    idx = 0\n",
    "\n",
    "    # accumulation moyenne par requête\n",
    "    per_k = {k: {\"ndcg\": [], \"mrr\": [], \"hit\": [], \"p\": [], \"r\": []} for k in ks}\n",
    "\n",
    "    for g in group:\n",
    "        y_g = np.asarray(y_true[idx: idx + g])\n",
    "        s_g = np.asarray(y_score[idx: idx + g])\n",
    "        idx += g\n",
    "\n",
    "        order = np.argsort(-s_g)  # desc\n",
    "        rels_sorted = y_g[order]\n",
    "\n",
    "        for k in ks:\n",
    "            per_k[k][\"ndcg\"].append(ndcg_at_k(rels_sorted, k))\n",
    "            per_k[k][\"mrr\"].append(mrr_at_k(rels_sorted, k))\n",
    "            per_k[k][\"hit\"].append(hit_rate_at_k(rels_sorted, k))\n",
    "            per_k[k][\"p\"].append(precision_at_k(rels_sorted, k))\n",
    "            per_k[k][\"r\"].append(recall_at_k(rels_sorted, k))\n",
    "    for k in ks:\n",
    "        metrics[f\"ndcg@{k}\"] = float(np.mean(per_k[k][\"ndcg\"]))\n",
    "        metrics[f\"mrr@{k}\"] = float(np.mean(per_k[k][\"mrr\"]))\n",
    "        metrics[f\"hit_rate@{k}\"] = float(np.mean(per_k[k][\"hit\"]))\n",
    "        metrics[f\"precision@{k}\"] = float(np.mean(per_k[k][\"p\"]))\n",
    "        metrics[f\"recall@{k}\"] = float(np.mean(per_k[k][\"r\"]))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f176fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Definir les groups train pour les algo de ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialiser MlFlow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5555\")\n",
    "client = mlflow.MlflowClient()\n",
    "mlflow.set_experiment(\"Algo_recommandation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf49f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Boucle MLflow\n",
    "for model_name, config in models.items():\n",
    "    model_class = config[\"model_class\"]\n",
    "    param_grid = config[\"param_grid\"]\n",
    "    fixed_params = config[\"fixed_params\"]\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        full_params = {**params, **fixed_params}\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tags({\n",
    "                \"model\": model_name,\n",
    "                \"experiment\": \"stockout_substitution_reco_comparison\",\n",
    "                \"task\": \"ranking\" if model_name == \"LGBMRanker\" else \"binary_classification\",\n",
    "            })\n",
    "\n",
    "            mlflow.log_params(full_params)\n",
    "\n",
    "            try:\n",
    "                model = model_class(**full_params)\n",
    "\n",
    "                if model_name == \"LGBMRanker\":\n",
    "                    # IMPORTANT: LightGBM Ranker nécessite group_train/group_val (ta granularité = stockout event)\n",
    "                    # y_train = pertinence du candidat substitut (0/1 ou grades)\n",
    "                    model.fit(\n",
    "                        X_train, y_train,\n",
    "                        group=group_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_group=[group_val],\n",
    "                    )\n",
    "\n",
    "                    val_scores = model.predict(X_val)\n",
    "                    rank_metrics = compute_ranking_metrics(y_val, val_scores, group_val, ks=(1, 3, 5))\n",
    "                    mlflow.log_metrics(rank_metrics)\n",
    "\n",
    "                    # Logger le modèle (MLflow LightGBM si dispo, sinon sklearn)\n",
    "                    try:\n",
    "                        import mlflow.lightgbm\n",
    "                        mlflow.lightgbm.log_model(model, \"model\")\n",
    "                    except Exception:\n",
    "                        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "                else:\n",
    "                    # CLASSIFICATION\n",
    "                    # (Si tu as un déséquilibre, pense à pondérer: class_weight='balanced' / scale_pos_weight pour XGB)\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                    # proba pour métriques probabilistes\n",
    "                    if hasattr(model, \"predict_proba\"):\n",
    "                        proba = model.predict_proba(X_val)[:, 1]\n",
    "                    else:\n",
    "                        # fallback (rare)\n",
    "                        proba = model.predict(X_val)\n",
    "\n",
    "                    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "                    metrics = {\n",
    "                        \"auc\": float(roc_auc_score(y_val, proba)) if len(np.unique(y_val)) > 1 else np.nan,\n",
    "                        \"pr_auc\": float(average_precision_score(y_val, proba)) if len(np.unique(y_val)) > 1 else np.nan,\n",
    "                        \"logloss\": float(log_loss(y_val, proba, eps=1e-15)),\n",
    "                        \"precision\": float(precision_score(y_val, pred, zero_division=0)),\n",
    "                        \"recall\": float(recall_score(y_val, pred, zero_division=0)),\n",
    "                        \"f1\": float(f1_score(y_val, pred, zero_division=0)),\n",
    "                    }\n",
    "\n",
    "                    # BONUS: métriques de ranking même pour les classif (on score et on trie)\n",
    "                    # Nécessite group_val pour pouvoir calculer topK par stockout event.\n",
    "                    if \"group_val\" in globals() and group_val is not None:\n",
    "                        metrics.update(compute_ranking_metrics(y_val, proba, group_val, ks=(1, 3, 5)))\n",
    "\n",
    "                    mlflow.log_metrics(metrics)\n",
    "\n",
    "                    # Logger le modèle selon lib\n",
    "                    if model_name == \"XGBClassifier\":\n",
    "                        try:\n",
    "                            import mlflow.xgboost\n",
    "                            mlflow.xgboost.log_model(model, \"model\")\n",
    "                        except Exception:\n",
    "                            mlflow.sklearn.log_model(model, \"model\")\n",
    "                    elif model_name in [\"LGBMClassifier\"]:\n",
    "                        try:\n",
    "                            import mlflow.lightgbm\n",
    "                            mlflow.lightgbm.log_model(model, \"model\")\n",
    "                        except Exception:\n",
    "                            mlflow.sklearn.log_model(model, \"model\")\n",
    "                    elif model_name == \"CatBoostClassifier\":\n",
    "                        try:\n",
    "                            import mlflow.catboost\n",
    "                            mlflow.catboost.log_model(model, \"model\")\n",
    "                        except Exception:\n",
    "                            mlflow.sklearn.log_model(model, \"model\")\n",
    "                    else:\n",
    "                        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "            except Exception as e:\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "                raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
